{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook to train and evaluate Yolo Mlt (Yolov5 small for object detection and image classification)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As of today (December 2nd 2022), the goal is to detect [speed signs, road work signs/objects, the horizon of the road] and to classify the road condition [dry/snowy/wet]."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/selim/Desktop/yolov5_multitask'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the detection task on esmart_wip dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by training the detection task with all layers activated (besides the classification head just as a security)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mselimgilon\u001B[0m (\u001B[33mesmart\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mmultitasks/train: \u001B[0mweights=runs/train-mlt/exp137/weights/best.pt, cfg=models/yolov5s_mlt.yaml, data=../datasets/esmart_wip/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=150, batch_size=32, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-mlt, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[25], freeze_till=[0], freeze_all_but=[], only_cls=False, only_det=True, save_period=-1, seed=0, local_rank=-1, mlt=[0], entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 41 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\r\n",
      "YOLOv5 üöÄ v6.2-264-g5cc2c799 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic_det=1.0, mosaic_cls=0.0, mixup=0.0, copy_paste=0.0, cls_road_cond=0\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.13.5 is available!  To upgrade, please run:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/selim/Desktop/yolov5_multitask/wandb/run-20221130_173621-1e5igsi7\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mwandering-aardvark-177\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/1e5igsi7\u001B[0m\r\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "Overriding model.yaml nc=80 with nc=10\r\n",
      "Multitasks: True\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      " 25                 8  1    661763  models.common.Classify                  [512, 3]                      \r\n",
      "YOLOv5s_mlt summary: 221 layers, 7708362 parameters, 7708362 gradients\r\n",
      "\r\n",
      "Transferred 356/357 items from runs/train-mlt/exp137/weights/best.pt\r\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ‚úÖ\r\n",
      "freezing model.25.conv.conv.weight\r\n",
      "freezing model.25.conv.bn.weight\r\n",
      "freezing model.25.conv.bn.bias\r\n",
      "freezing model.25.linear.weight\r\n",
      "freezing model.25.linear.bias\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.1) with parameter groups 58 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\r\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mRandomResizedCrop(p=1, height=512, width=512, scale=(0.6, 1.0), ratio=(0.7, 1.11), interpolation=1), HorizontalFlip(p=0.2), Blur(p=0.2, blur_limit=(3, 7)), ToGray(p=0.1), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), CLAHE(p=0.2, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.2, gamma_limit=(80, 120), eps=None), ImageCompression(p=0.2, quality_lower=75, quality_upper=100, compression_type=0)\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/train.ca\u001B[0m\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210629_173500_5409.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_28266.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_37434.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_3444.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_6540.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_11838.jpg: 9 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_13446.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_8160.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13344.jpg: 8 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13470.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_42354.jpg: 30 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_9444.jpg: 13 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_33644.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_4542.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210715_091801_14454.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210724_113301_14106.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_12738.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_33438.jpg: 1 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg'\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/val.cache'\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/run_7_12704.jpg: 8 duplicate labels removed\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.92 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train-mlt/exp144/labels.jpg... \r\n",
      "Image sizes 512 train, 512 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train-mlt/exp144\u001B[0m\r\n",
      "Starting training for 150 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      0/149      4.22G     0.1002    0.02301    0.04289          0        157   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319      0.213     0.0964      0.026    0.00599     0.5033     0.4438     0.4967       0.47       0.71\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      1/149      5.17G    0.09029    0.02053     0.0276          0        104   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.424     0.0642     0.0423     0.0111     0.8941     0.3333     0.1059     0.2704      0.689\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      2/149      5.17G    0.08566     0.0203    0.02361          0         98   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1307      0.762     0.0619     0.0477     0.0162     0.4118     0.2957     0.5882     0.1241      0.205\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      3/149      5.17G    0.08034    0.01978    0.02058          0        152   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317       0.68     0.0875      0.108     0.0392     0.2462     0.2468     0.7538     0.1996       0.25\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      4/149      5.17G    0.07708    0.01936    0.01837          0        184   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.652      0.171      0.129     0.0483     0.3179     0.3346     0.6821      0.326      0.573\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      5/149      5.17G    0.07477    0.01913     0.0175          0        156   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.729       0.12      0.161     0.0687     0.1713     0.3176     0.8287     0.1617      0.227\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      6/149      5.17G    0.07395    0.01928    0.01748          0        144   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1320      0.904      0.177       0.21     0.0931     0.7597     0.3333     0.2403     0.1455       0.25\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      7/149      5.17G    0.07235    0.01857    0.01612          0        128   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1303      0.541      0.219      0.179     0.0739     0.7335      0.335     0.2665     0.2793      0.679\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      8/149      5.17G    0.07132    0.01883    0.01573          0        150   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1308      0.395      0.174      0.182     0.0872     0.5165     0.4652     0.4835     0.4671      0.778\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      9/149      5.17G     0.0705    0.01839    0.01487          0        128   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1321      0.428      0.237      0.227      0.104     0.4166     0.4495     0.5834     0.3877      0.599\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     10/149      5.17G    0.06967    0.01808    0.01423          0        130   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319      0.418      0.234      0.216     0.0931     0.6634     0.3427     0.3366     0.3167      0.627\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     11/149      5.17G     0.0696    0.01796    0.01449          0        142   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1286      0.462      0.242       0.23        0.1     0.6018     0.3037     0.3982     0.2801      0.576\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     12/149      5.17G     0.0688    0.01804    0.01389          0        110   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1335      0.367       0.23      0.218      0.102     0.3878     0.3368     0.6122     0.1549      0.273\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     13/149      5.17G    0.06862    0.01796    0.01407          0        140   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.431      0.235      0.223     0.0948      0.896     0.3333      0.104     0.2717      0.668\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     14/149      5.17G    0.06824    0.01797    0.01299          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1294      0.416      0.283      0.205     0.0965     0.8889     0.3333     0.1111     0.2667      0.675\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     15/149      5.17G    0.06769     0.0178    0.01307          0        152   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1315      0.595      0.213      0.224     0.0923     0.4928     0.4749     0.5072     0.4332      0.759\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     16/149      5.17G    0.06743     0.0179    0.01324          0        119   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1295      0.393      0.258      0.219      0.103     0.7957     0.4136     0.2043     0.4047       0.75\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     17/149      5.17G    0.06729    0.01763    0.01286          0        127   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1344      0.558       0.23      0.252      0.111     0.2466     0.2584     0.7534     0.2272      0.325\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     18/149      5.17G    0.06648     0.0177    0.01274          0        174   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.436      0.241      0.252      0.117     0.2706       0.18     0.7294     0.2126      0.273\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     19/149      5.17G    0.06706    0.01769    0.01242          0        127   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1311      0.436      0.256       0.24      0.108     0.2493     0.2555     0.7507     0.2431      0.479\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     20/149      5.17G     0.0659    0.01751    0.01184          0        185   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1328      0.464       0.26      0.248      0.119     0.3293     0.3301     0.6707     0.3062      0.604\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     21/149      5.17G    0.06629    0.01758    0.01213          0        120   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1301      0.455       0.21      0.214      0.102     0.6758     0.3381     0.3242     0.2976      0.674\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     22/149      5.17G    0.06619    0.01727    0.01226          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1303      0.474      0.277      0.235        0.1     0.2879     0.2269     0.7121      0.249      0.273\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     23/149      5.17G    0.06521    0.01735    0.01163          0        124   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1336       0.41      0.258      0.232      0.107     0.8953     0.3333     0.1047     0.2713      0.693\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     24/149      5.17G    0.06526     0.0175    0.01158          0         96   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1301      0.432      0.238      0.235      0.113     0.3659     0.3101     0.6341     0.3042      0.401\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     25/149      5.17G    0.06481    0.01739     0.0114          0        117   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1281      0.469      0.277      0.251      0.119     0.5774     0.3205     0.4226     0.2674      0.663\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     26/149      5.17G    0.06545    0.01749    0.01196          0        139   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1349      0.487      0.251      0.235      0.114     0.1528     0.1258     0.8472     0.1276      0.189\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     27/149      5.17G     0.0649    0.01744    0.01118          0        123   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1297      0.461      0.241       0.25      0.118     0.7023     0.3837     0.2977     0.3752      0.689\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     28/149      5.17G    0.06467    0.01713    0.01137          0        107   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1299       0.43       0.25      0.247      0.118      0.896     0.3333      0.104     0.2717       0.72\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     29/149      5.17G    0.06514    0.01715    0.01126          0        102   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1306      0.457      0.293      0.279      0.128     0.6731     0.3601     0.3269     0.3431      0.545\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     30/149      5.17G    0.06471    0.01719     0.0112          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1326      0.503      0.283      0.272      0.131     0.2202     0.1641     0.7798     0.1794       0.22\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     31/149      5.17G    0.06437    0.01717    0.01072          0        159   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1294      0.475      0.264      0.276      0.127     0.2445     0.2687     0.7555     0.1769       0.26\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     32/149      5.17G    0.06416    0.01693    0.01076          0        112   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.495      0.274      0.254      0.118     0.2235     0.2481     0.7765     0.2321      0.474\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     33/149      5.17G    0.06426    0.01706    0.01062          0        153   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1340      0.446       0.27      0.261      0.127     0.4236     0.3343     0.5764     0.1439      0.318\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     34/149      5.17G    0.06402    0.01712    0.01085          0        124   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.429      0.287      0.257      0.129     0.4527     0.3278     0.5473     0.1744      0.252\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     35/149      5.17G    0.06377    0.01699    0.01067          0        146   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1320      0.468      0.289       0.27      0.131     0.5627     0.3185     0.4373     0.2667      0.701\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     36/149      5.17G    0.06384     0.0168       0.01          0        129   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1299      0.471      0.294       0.27      0.128     0.1576     0.3036     0.8424     0.1395      0.281\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     37/149      5.17G    0.06337    0.01697    0.01021          0        135   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1329      0.475      0.296       0.28      0.133     0.1416     0.2415     0.8584       0.13      0.177\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     38/149      5.17G    0.06332    0.01675    0.01044          0        123   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1304      0.499      0.253      0.265      0.127     0.4978     0.3189     0.5022     0.1539      0.269\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     39/149      5.17G    0.06353    0.01713    0.01049          0         90   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1305      0.453       0.29       0.28      0.137      0.441     0.3036      0.559     0.1743      0.217\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     40/149      5.17G    0.06318    0.01683    0.01027          0        118   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1320      0.472      0.281      0.276      0.132     0.6189     0.2955     0.3811      0.275      0.406\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     41/149      5.17G    0.06318    0.01701    0.01034          0        137   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1302      0.433       0.33      0.283      0.132     0.5163     0.3077     0.4837     0.1527      0.234\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     42/149      5.17G    0.06269    0.01683   0.009847          0        151   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.416      0.293      0.255      0.128     0.2821     0.2823     0.7179     0.2729      0.439\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     43/149      5.17G    0.06259    0.01666    0.01022          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1305      0.484      0.291      0.272      0.135     0.6543     0.3538     0.3457     0.2543      0.413\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     44/149      5.17G     0.0625    0.01675   0.009942          0        111   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1310      0.458      0.335      0.277      0.141      0.267     0.2414      0.733     0.2422      0.356\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     45/149      5.17G    0.06281    0.01678   0.009745          0        125   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1324      0.502      0.296      0.279      0.136     0.5792     0.2485     0.4208     0.2451      0.457\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     46/149      5.17G    0.06285    0.01673    0.01003          0        133   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1315      0.454      0.285      0.267      0.131     0.5642     0.2413     0.4358      0.236      0.457\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     47/149      5.17G    0.06242    0.01686   0.009656          0        126   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.481      0.295      0.286      0.139     0.4297     0.3543     0.5703     0.2134      0.335\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     48/149      5.17G    0.06227    0.01669   0.009426          0        112   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319        0.5      0.294      0.275      0.135     0.2398     0.2362     0.7602     0.2368      0.462\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     49/149      5.17G    0.06207    0.01692   0.009872          0        132   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1298      0.486      0.294      0.282      0.138     0.1277     0.1557     0.8723     0.1139      0.175\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     50/149      5.17G    0.06207    0.01698   0.009463          0        126   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1298      0.487      0.345      0.297      0.145    0.09125     0.3176     0.9087     0.1418      0.236\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     51/149      5.17G    0.06169    0.01673   0.009447          0        130   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.488      0.292      0.271      0.139     0.5188     0.1902     0.4812     0.1651      0.271\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     52/149      5.17G    0.06211    0.01646   0.009462          0        186   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1300      0.491      0.296      0.284      0.138    0.06706     0.1473     0.9329    0.08316      0.193\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     53/149      5.17G    0.06182    0.01669   0.009126          0        150   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1336      0.467      0.335      0.297      0.143     0.1115     0.2223     0.8885     0.1196        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     54/149      5.17G    0.06175    0.01669   0.009233          0        129   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1302      0.468      0.308      0.286      0.143     0.4456     0.3308     0.5544     0.1676      0.227\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     55/149      5.17G     0.0618    0.01649   0.009571          0        148   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1292      0.534       0.28      0.291      0.147     0.2677     0.2923     0.7323     0.1891      0.281\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     56/149      5.17G    0.06142    0.01659   0.009079          0        132   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1330      0.485      0.322      0.285      0.144     0.5532     0.2473     0.4468     0.1894      0.248\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     57/149      5.17G    0.06114     0.0165   0.008677          0        151   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1314      0.458      0.323      0.285      0.146     0.1103     0.2004     0.8897      0.117      0.161\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     58/149      5.17G    0.06163     0.0165   0.009064          0        137   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1292      0.487      0.322      0.287      0.143      0.541      0.194      0.459     0.1957      0.299\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     59/149      5.17G     0.0612     0.0167   0.009073          0        148   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1343      0.495      0.304      0.305       0.15    0.08313     0.2607     0.9169     0.1261      0.181\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     60/149      5.17G    0.06147    0.01663    0.00949          0        130   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1299      0.516      0.267      0.277      0.138      0.235     0.2341      0.765     0.2118      0.299\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     61/149      5.17G     0.0611     0.0164   0.008784          0         98   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1302      0.467      0.327      0.294      0.147      0.522     0.1983      0.478     0.1662      0.219\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     62/149      5.17G    0.06077    0.01642   0.009415          0        163   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1309      0.483      0.313       0.29      0.149     0.2207     0.2145     0.7793     0.1984      0.323\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     63/149      5.17G    0.06066    0.01621    0.00887          0        117   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.469      0.298      0.284      0.146     0.5511     0.2456     0.4489     0.1895      0.274\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     64/149      5.17G     0.0608    0.01626   0.008619          0        108   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1324      0.493      0.301      0.283      0.145     0.2618     0.2906     0.7382     0.2254      0.292\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     65/149      5.17G    0.06063    0.01638   0.008264          0        128   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1284      0.507      0.338      0.308       0.15     0.5636     0.2992     0.4364     0.1725      0.354\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     66/149      5.17G    0.06042    0.01627   0.008738          0        125   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1362      0.517      0.311      0.296      0.146     0.6341     0.3249     0.3659      0.278      0.396\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     67/149      5.17G    0.06043    0.01645   0.008755          0         97   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1290      0.499      0.314      0.286      0.145      0.562     0.2328      0.438     0.1995      0.318\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     68/149      5.17G    0.06043    0.01646   0.008308          0        136   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1306      0.492      0.286      0.286      0.145     0.6972     0.3731     0.3028     0.2942      0.436\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     69/149      5.17G    0.06053    0.01632   0.008577          0        100   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1283       0.51      0.318      0.295      0.146     0.7053     0.3677     0.2947      0.264      0.429\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     70/149      5.17G    0.06013    0.01639   0.008369          0        190   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1325      0.516      0.312      0.292      0.147     0.1417      0.206     0.8583     0.1258      0.196\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     71/149      5.17G    0.05991    0.01627   0.008279          0        136   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.523      0.321      0.299      0.149     0.1249     0.1337     0.8751     0.1102      0.141\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     72/149      5.17G    0.05971    0.01628   0.008145          0        105   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.527      0.334      0.316      0.158     0.1352     0.2747     0.8648     0.1373      0.255\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     73/149      5.17G    0.05981    0.01611   0.007835          0        101   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1326      0.496      0.312      0.295       0.15     0.3507     0.3613     0.6493     0.2578      0.392\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     74/149      5.17G    0.06011    0.01618    0.00803          0         94   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1293      0.474      0.338       0.31      0.158     0.5904     0.3195     0.4096     0.1521      0.286\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     75/149      5.17G     0.0595    0.01625   0.007854          0        114   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1310      0.452      0.316      0.282      0.149     0.1782     0.3119     0.8218     0.1459       0.24\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     76/149      5.17G    0.05986    0.01619   0.008204          0        133   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1325      0.502      0.329      0.307      0.157     0.5521     0.2302     0.4479     0.1884      0.274\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     77/149      5.17G    0.05902    0.01587   0.007871          0        118   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1310      0.526       0.32        0.3      0.156       0.26     0.3192       0.74     0.1533      0.264\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     78/149      5.17G    0.05892    0.01602    0.00801          0        151   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1297      0.544      0.331      0.315      0.157      0.545     0.2171      0.455     0.1897      0.252\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     79/149      5.17G    0.05919    0.01614   0.007957          0        115   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1308      0.513      0.347      0.314      0.159     0.5559     0.2767     0.4441     0.1741      0.238\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     80/149      5.17G    0.05887    0.01596   0.007743          0        153   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1311      0.508      0.324       0.31      0.155     0.6328     0.3256     0.3672     0.2542      0.359\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     81/149      5.17G     0.0589    0.01608   0.007732          0        155   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1327      0.514      0.335      0.311      0.154     0.5798     0.2684     0.4202     0.2076      0.299\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     82/149      5.17G     0.0588    0.01592   0.007485          0        115   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1342      0.547      0.327      0.328      0.162     0.5499     0.2296     0.4501     0.1931       0.28\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     83/149      5.17G    0.05869    0.01604   0.007481          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1277      0.496      0.331      0.306      0.155     0.5187     0.2382     0.4813     0.1538      0.233\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     84/149      5.17G    0.05843    0.01594   0.007612          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1311       0.53      0.341      0.322      0.156     0.4983      0.164     0.5017     0.1449      0.271\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     85/149      5.17G    0.05888    0.01578   0.007761          0        144   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.541       0.32      0.318      0.162    0.09112     0.2636     0.9089     0.1198      0.188\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     86/149      5.17G    0.05849    0.01606   0.007122          0        115   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1304       0.53      0.322      0.311      0.156     0.5079     0.2718     0.4921     0.1462      0.212\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     87/149      5.17G    0.05856    0.01586   0.007274          0        132   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1296      0.513      0.334      0.318      0.158     0.5656      0.313     0.4344     0.1638      0.276\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     88/149      5.17G    0.05794    0.01586   0.007238          0        142   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1321      0.542      0.333      0.326      0.162     0.5278     0.2388     0.4722     0.1615       0.24\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     89/149      5.17G    0.05852    0.01606   0.007249          0         96   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1314      0.537      0.315       0.31      0.156      0.532     0.2447      0.468     0.1678      0.274\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     90/149      5.17G     0.0578     0.0161   0.007145          0        151   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1308      0.562      0.326      0.329       0.16     0.5399     0.2929     0.4601     0.1523       0.25\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     91/149      5.17G    0.05827     0.0157    0.00704          0        140   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1328      0.528      0.341      0.318      0.162     0.5511      0.283     0.4489     0.1725       0.24\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     92/149      5.17G    0.05769    0.01589   0.007234          0        180   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319      0.561      0.321      0.332      0.163      0.577     0.3207      0.423     0.1645      0.271\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     93/149      5.17G    0.05772    0.01602   0.007233          0        116   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.522      0.335      0.307       0.16     0.2416     0.2952     0.7584     0.1874      0.337\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     94/149      5.17G    0.05767    0.01568   0.006748          0        120   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.495      0.336      0.316      0.159     0.5349     0.2905     0.4651     0.1517       0.22\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     95/149      5.17G     0.0574    0.01587   0.006842          0        138   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1301      0.573      0.349      0.348      0.168     0.2268     0.3039     0.7732     0.1607      0.271\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     96/149      5.17G    0.05743    0.01582    0.00699          0        121   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.557      0.334      0.333      0.163     0.5278      0.275     0.4722     0.1598      0.222\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     97/149      5.17G    0.05706    0.01562   0.006867          0         96   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1330      0.582      0.332      0.332      0.166     0.2419     0.2913     0.7581     0.1879       0.28\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     98/149      5.17G    0.05744    0.01565   0.006689          0        125   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1299      0.568      0.337      0.322      0.162     0.5716     0.2682     0.4284     0.2105      0.352\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "     99/149      5.17G    0.05726    0.01563   0.006741          0        106   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1288      0.533      0.332      0.313      0.161     0.6011     0.3082     0.3989     0.1767      0.248\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    100/149      5.17G    0.05685    0.01578   0.006448          0        145   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1330      0.559       0.34      0.336      0.166     0.6121     0.3089     0.3879     0.2206      0.347\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    101/149      5.17G    0.05713    0.01568   0.006851          0        123   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.527      0.317      0.301      0.159      0.591     0.2946      0.409     0.2043      0.321\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    102/149      5.17G    0.05664    0.01559    0.00628          0        127   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.532      0.327       0.32      0.163     0.6132     0.3068     0.3868     0.2143      0.286\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    103/149      5.17G    0.05655    0.01555   0.005992          0        118   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1330       0.53      0.311      0.311      0.162     0.5601     0.2736     0.4399      0.182      0.269\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    104/149      5.17G    0.05675    0.01557   0.006491          0        130   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1321      0.542      0.317      0.319      0.162     0.5236     0.2327     0.4764     0.1675      0.297\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    105/149      5.17G    0.05617    0.01576   0.006128          0        153   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1296      0.564      0.319      0.333      0.167     0.5248     0.2361     0.4752     0.1721      0.255\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    106/149      5.17G    0.05617    0.01584   0.006343          0        148   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1314       0.54      0.321       0.31       0.16     0.5367     0.2481     0.4633     0.1789      0.312\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    107/149      5.17G    0.05636    0.01539   0.006197          0        121   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1321      0.558      0.342       0.33      0.167     0.5353     0.2209     0.4647     0.1758      0.283\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    108/149      5.17G    0.05628     0.0153   0.006051          0        137   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1300       0.55      0.336      0.312      0.161     0.5174     0.1987     0.4826     0.1666      0.219\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    109/149      5.17G    0.05552    0.01524   0.005877          0         99   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1323      0.538      0.346      0.325      0.167     0.5159      0.181     0.4841     0.1569      0.236\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    110/149      5.17G    0.05544    0.01537   0.005887          0         99   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1332      0.571      0.336      0.329      0.166     0.5052     0.1875     0.4948     0.1496      0.248\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    111/149      5.17G    0.05519    0.01543   0.005847          0        158   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1276      0.544      0.323       0.32      0.164     0.4841     0.1716     0.5159     0.1379      0.207\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    112/149      5.17G    0.05508    0.01557   0.005398          0        112   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1307      0.564       0.33      0.327      0.164     0.5016     0.1684     0.4984     0.1457      0.247\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    113/149      5.17G    0.05508    0.01542   0.005816          0        142   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1307      0.542      0.316      0.318      0.163     0.5067     0.1719     0.4933     0.1541      0.207\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    114/149      5.17G    0.05502    0.01544   0.005853          0        132   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1295      0.542      0.314      0.318      0.163      0.496     0.1636      0.504     0.1436      0.217\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    115/149      5.17G     0.0552    0.01524   0.005504          0        132   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1338      0.558      0.329      0.325      0.163     0.4842     0.1564     0.5158     0.1341      0.177\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    116/149      5.17G    0.05479    0.01512   0.005581          0        143   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1301      0.541      0.336      0.325      0.167     0.4931     0.1548     0.5069     0.1371      0.184\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    117/149      5.17G    0.05486    0.01531   0.005221          0        113   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1330      0.539       0.31      0.307      0.156     0.4924     0.1695     0.5076     0.1441      0.215\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    118/149      5.17G    0.05397    0.01541   0.005133          0        114   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1303      0.534      0.333       0.32      0.164     0.4907     0.1679     0.5093     0.1399      0.236\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    119/149      5.17G    0.05402    0.01511    0.00537          0         92   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312       0.55      0.332      0.327      0.166     0.4994     0.1793     0.5006     0.1455      0.269\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    120/149      5.17G    0.05438    0.01522   0.005354          0        136   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.534      0.353      0.326      0.164     0.4965     0.1916     0.5035      0.143      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    121/149      5.17G    0.05383    0.01511   0.005055          0        162   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1311       0.53      0.353      0.337      0.168     0.4931      0.172     0.5069     0.1416      0.212\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    122/149      5.17G    0.05374    0.01491   0.005096          0        111   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1326      0.507      0.343      0.312      0.163     0.5034     0.1938     0.4966     0.1497      0.196\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    123/149      5.17G     0.0535    0.01517   0.004963          0        157   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1273      0.515      0.339      0.329      0.164     0.4866     0.1967     0.5134     0.1402      0.288\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    124/149      5.17G     0.0537    0.01504   0.004895          0        124   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1336       0.52      0.345      0.329      0.168     0.4914     0.1977     0.5086     0.1395      0.236\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    125/149      5.17G    0.05359    0.01497   0.004773          0        165   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1324      0.521      0.372      0.337      0.167     0.4951     0.2084     0.5049     0.1471       0.22\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    126/149      5.17G    0.05328    0.01505   0.004768          0        167   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317       0.53      0.346      0.329      0.165     0.5049     0.2241     0.4951       0.15        0.2\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    127/149      5.17G    0.05304    0.01507   0.004537          0        123   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1302      0.517      0.334      0.313      0.161      0.504     0.2213      0.496     0.1484      0.222\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "    128/149      5.17G    0.05281     0.0147   0.004359          0        121   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1288      0.563      0.361      0.344      0.171     0.5108     0.2267     0.4892     0.1593      0.264\r\n",
      "Stopping training early as no improvement observed in last 100 epochs. Best results observed at epoch 28, best model saved as best.pt.\r\n",
      "To update EarlyStopping(patience=100) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\r\n",
      "\r\n",
      "129 epochs completed in 1.835 hours.\r\n",
      "Optimizer stripped from runs/train-mlt/exp144/weights/last.pt, 15.7MB\r\n",
      "Optimizer stripped from runs/train-mlt/exp144/weights/best.pt, 15.7MB\r\n",
      "\r\n",
      "Validating runs/train-mlt/exp144/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 163 layers, 7697578 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1313      0.596      0.245      0.251      0.123     0.8979     0.3333     0.1021     0.2731      0.674\r\n",
      "         speed_limit        516        630      0.826      0.843      0.885      0.548\r\n",
      "              rw_tcd        516        202      0.453      0.465       0.44      0.148\r\n",
      "             highway        516        300      0.295      0.163      0.141     0.0323\r\n",
      "         interchange        516          4          1          0          0          0\r\n",
      "               urban        516        124          1          0     0.0128    0.00214\r\n",
      "         rural-paved        516         53          0          0     0.0306    0.00689\r\n",
      "                 dry        516        358          -          -          -          -      0.694          1      0.306      0.819\r\n",
      "               snowy        516         27          -          -          -          -          1          0          0          0\r\n",
      "                 wet        516        131          -          -          -          -          1          0          0          0\r\n",
      "Results saved to \u001B[1mruns/train-mlt/exp144\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[32m(success).\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet ‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet ‚ñÅ‚ñÖ‚ñÅ‚ñá‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñá‚ñá‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val ‚ñà‚ñÇ‚ñà‚ñá‚ñà‚ñÉ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÉ‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÉ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls ‚ñà‚ñÇ‚ñá‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_cls 0.89599\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/P_snowy 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_wet 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_cls 0.33333\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/R_snowy 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_wet 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     best/cls_acc_val 0.72\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/epoch 28\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/mAP_0.5 0.24665\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    best/mAP_0.5:0.95 0.11841\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       best/precision 0.42975\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          best/recall 0.24954\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet 0.20672\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet 0.55944\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val 0.264\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 0.12276\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 0.89793\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls 0.33333\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision 0.24525\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall 0.2514\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss 0.05281\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss 0.00436\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss 0.59566\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss 0.0147\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss 0.05041\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss 0.0098\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss 2.03223\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss 0.00901\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 0.01618\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 0.01618\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 0.01618\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced \u001B[33mwandering-aardvark-177\u001B[0m: \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/1e5igsi7\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 280 media file(s), 1 artifact file(s) and 0 other file(s)\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20221130_173621-1e5igsi7/logs\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python multitasks/train.py --epochs 30 --img 512 --weights yolo5s.pt --data ../datasets/esmart_wip/data.yaml --batch-size 32 --only_det --freeze 25"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/train-mlt/exp144\n"
     ]
    }
   ],
   "source": [
    "# get the last folder of the folder runs/train-mlt/\n",
    "list_of_files = glob.glob('runs/train-mlt/*')\n",
    "latest_exp_path = max(list_of_files, key=os.path.getmtime)\n",
    "print(latest_exp_path)\n",
    "last_weights = f\"{latest_exp_path}/weights/last.pt\"\n",
    "best_weights = f\"{latest_exp_path}/weights/best.pt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the classification task on esmart_context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train only the classification using the weights form the previous run and freezing every layer besides the classification head (and optionally the layer before #8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mselimgilon\u001B[0m (\u001B[33mesmart\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mmultitasks/train: \u001B[0mweights=runs/train-mlt/exp112/weights/best.pt, cfg=models/yolov5s_mlt.yaml, data=../datasets/esmart_context/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=32, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-mlt, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, cut_img=0.5, patience=100, freeze=[], freeze_all=False, freeze_till=[0], freeze_all_but=[8, 25], only_cls=True, only_det=False, save_period=-1, seed=0, local_rank=-1, mlt=[0], entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 56 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic_det=1.0, mosaic_cls=0.0, mixup=0.0, copy_paste=0.0, cls_road_cond=1\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "2022-12-08 11:24:04.601504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-12-08 11:24:06.018985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 11:24:06.019048: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 11:24:06.019056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.13.6 is available!  To upgrade, please run:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/selim/Desktop/yolov5_multitask/wandb/run-20221208_112406-38v2wwy5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mdark-fog-213\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/38v2wwy5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "Overriding model.yaml nc=80 with nc=10\r\n",
      "Multitasks: True\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      " 25                 8  1    661763  models.common.Classify                  [512, 3]                      \r\n",
      "YOLOv5s_mlt summary: 222 layers, 7708362 parameters, 7708362 gradients, 48.1 GFLOPs\r\n",
      "\r\n",
      "Transferred 356/551 items from runs/train-mlt/exp112/weights/best.pt\r\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ‚úÖ\r\n",
      "freezing model.0.conv.weight\r\n",
      "freezing model.0.bn.weight\r\n",
      "freezing model.0.bn.bias\r\n",
      "freezing model.1.conv.weight\r\n",
      "freezing model.1.bn.weight\r\n",
      "freezing model.1.bn.bias\r\n",
      "freezing model.2.cv1.conv.weight\r\n",
      "freezing model.2.cv1.bn.weight\r\n",
      "freezing model.2.cv1.bn.bias\r\n",
      "freezing model.2.cv2.conv.weight\r\n",
      "freezing model.2.cv2.bn.weight\r\n",
      "freezing model.2.cv2.bn.bias\r\n",
      "freezing model.2.cv3.conv.weight\r\n",
      "freezing model.2.cv3.bn.weight\r\n",
      "freezing model.2.cv3.bn.bias\r\n",
      "freezing model.2.m.0.cv1.conv.weight\r\n",
      "freezing model.2.m.0.cv1.bn.weight\r\n",
      "freezing model.2.m.0.cv1.bn.bias\r\n",
      "freezing model.2.m.0.cv2.conv.weight\r\n",
      "freezing model.2.m.0.cv2.bn.weight\r\n",
      "freezing model.2.m.0.cv2.bn.bias\r\n",
      "freezing model.3.conv.weight\r\n",
      "freezing model.3.bn.weight\r\n",
      "freezing model.3.bn.bias\r\n",
      "freezing model.4.cv1.conv.weight\r\n",
      "freezing model.4.cv1.bn.weight\r\n",
      "freezing model.4.cv1.bn.bias\r\n",
      "freezing model.4.cv2.conv.weight\r\n",
      "freezing model.4.cv2.bn.weight\r\n",
      "freezing model.4.cv2.bn.bias\r\n",
      "freezing model.4.cv3.conv.weight\r\n",
      "freezing model.4.cv3.bn.weight\r\n",
      "freezing model.4.cv3.bn.bias\r\n",
      "freezing model.4.m.0.cv1.conv.weight\r\n",
      "freezing model.4.m.0.cv1.bn.weight\r\n",
      "freezing model.4.m.0.cv1.bn.bias\r\n",
      "freezing model.4.m.0.cv2.conv.weight\r\n",
      "freezing model.4.m.0.cv2.bn.weight\r\n",
      "freezing model.4.m.0.cv2.bn.bias\r\n",
      "freezing model.4.m.1.cv1.conv.weight\r\n",
      "freezing model.4.m.1.cv1.bn.weight\r\n",
      "freezing model.4.m.1.cv1.bn.bias\r\n",
      "freezing model.4.m.1.cv2.conv.weight\r\n",
      "freezing model.4.m.1.cv2.bn.weight\r\n",
      "freezing model.4.m.1.cv2.bn.bias\r\n",
      "freezing model.5.conv.weight\r\n",
      "freezing model.5.bn.weight\r\n",
      "freezing model.5.bn.bias\r\n",
      "freezing model.6.cv1.conv.weight\r\n",
      "freezing model.6.cv1.bn.weight\r\n",
      "freezing model.6.cv1.bn.bias\r\n",
      "freezing model.6.cv2.conv.weight\r\n",
      "freezing model.6.cv2.bn.weight\r\n",
      "freezing model.6.cv2.bn.bias\r\n",
      "freezing model.6.cv3.conv.weight\r\n",
      "freezing model.6.cv3.bn.weight\r\n",
      "freezing model.6.cv3.bn.bias\r\n",
      "freezing model.6.m.0.cv1.conv.weight\r\n",
      "freezing model.6.m.0.cv1.bn.weight\r\n",
      "freezing model.6.m.0.cv1.bn.bias\r\n",
      "freezing model.6.m.0.cv2.conv.weight\r\n",
      "freezing model.6.m.0.cv2.bn.weight\r\n",
      "freezing model.6.m.0.cv2.bn.bias\r\n",
      "freezing model.6.m.1.cv1.conv.weight\r\n",
      "freezing model.6.m.1.cv1.bn.weight\r\n",
      "freezing model.6.m.1.cv1.bn.bias\r\n",
      "freezing model.6.m.1.cv2.conv.weight\r\n",
      "freezing model.6.m.1.cv2.bn.weight\r\n",
      "freezing model.6.m.1.cv2.bn.bias\r\n",
      "freezing model.6.m.2.cv1.conv.weight\r\n",
      "freezing model.6.m.2.cv1.bn.weight\r\n",
      "freezing model.6.m.2.cv1.bn.bias\r\n",
      "freezing model.6.m.2.cv2.conv.weight\r\n",
      "freezing model.6.m.2.cv2.bn.weight\r\n",
      "freezing model.6.m.2.cv2.bn.bias\r\n",
      "freezing model.7.conv.weight\r\n",
      "freezing model.7.bn.weight\r\n",
      "freezing model.7.bn.bias\r\n",
      "freezing model.8.cv1.conv.weight\r\n",
      "UNFREEZING model.8.cv1.conv.weight\r\n",
      "freezing model.8.cv1.bn.weight\r\n",
      "UNFREEZING model.8.cv1.bn.weight\r\n",
      "freezing model.8.cv1.bn.bias\r\n",
      "UNFREEZING model.8.cv1.bn.bias\r\n",
      "freezing model.8.cv2.conv.weight\r\n",
      "UNFREEZING model.8.cv2.conv.weight\r\n",
      "freezing model.8.cv2.bn.weight\r\n",
      "UNFREEZING model.8.cv2.bn.weight\r\n",
      "freezing model.8.cv2.bn.bias\r\n",
      "UNFREEZING model.8.cv2.bn.bias\r\n",
      "freezing model.8.cv3.conv.weight\r\n",
      "UNFREEZING model.8.cv3.conv.weight\r\n",
      "freezing model.8.cv3.bn.weight\r\n",
      "UNFREEZING model.8.cv3.bn.weight\r\n",
      "freezing model.8.cv3.bn.bias\r\n",
      "UNFREEZING model.8.cv3.bn.bias\r\n",
      "freezing model.8.m.0.cv1.conv.weight\r\n",
      "UNFREEZING model.8.m.0.cv1.conv.weight\r\n",
      "freezing model.8.m.0.cv1.bn.weight\r\n",
      "UNFREEZING model.8.m.0.cv1.bn.weight\r\n",
      "freezing model.8.m.0.cv1.bn.bias\r\n",
      "UNFREEZING model.8.m.0.cv1.bn.bias\r\n",
      "freezing model.8.m.0.cv2.conv.weight\r\n",
      "UNFREEZING model.8.m.0.cv2.conv.weight\r\n",
      "freezing model.8.m.0.cv2.bn.weight\r\n",
      "UNFREEZING model.8.m.0.cv2.bn.weight\r\n",
      "freezing model.8.m.0.cv2.bn.bias\r\n",
      "UNFREEZING model.8.m.0.cv2.bn.bias\r\n",
      "freezing model.9.cv1.conv.weight\r\n",
      "freezing model.9.cv1.bn.weight\r\n",
      "freezing model.9.cv1.bn.bias\r\n",
      "freezing model.9.cv2.conv.weight\r\n",
      "freezing model.9.cv2.bn.weight\r\n",
      "freezing model.9.cv2.bn.bias\r\n",
      "freezing model.10.conv.weight\r\n",
      "freezing model.10.bn.weight\r\n",
      "freezing model.10.bn.bias\r\n",
      "freezing model.13.cv1.conv.weight\r\n",
      "freezing model.13.cv1.bn.weight\r\n",
      "freezing model.13.cv1.bn.bias\r\n",
      "freezing model.13.cv2.conv.weight\r\n",
      "freezing model.13.cv2.bn.weight\r\n",
      "freezing model.13.cv2.bn.bias\r\n",
      "freezing model.13.cv3.conv.weight\r\n",
      "freezing model.13.cv3.bn.weight\r\n",
      "freezing model.13.cv3.bn.bias\r\n",
      "freezing model.13.m.0.cv1.conv.weight\r\n",
      "freezing model.13.m.0.cv1.bn.weight\r\n",
      "freezing model.13.m.0.cv1.bn.bias\r\n",
      "freezing model.13.m.0.cv2.conv.weight\r\n",
      "freezing model.13.m.0.cv2.bn.weight\r\n",
      "freezing model.13.m.0.cv2.bn.bias\r\n",
      "freezing model.14.conv.weight\r\n",
      "freezing model.14.bn.weight\r\n",
      "freezing model.14.bn.bias\r\n",
      "freezing model.17.cv1.conv.weight\r\n",
      "freezing model.17.cv1.bn.weight\r\n",
      "freezing model.17.cv1.bn.bias\r\n",
      "freezing model.17.cv2.conv.weight\r\n",
      "freezing model.17.cv2.bn.weight\r\n",
      "freezing model.17.cv2.bn.bias\r\n",
      "freezing model.17.cv3.conv.weight\r\n",
      "freezing model.17.cv3.bn.weight\r\n",
      "freezing model.17.cv3.bn.bias\r\n",
      "freezing model.17.m.0.cv1.conv.weight\r\n",
      "freezing model.17.m.0.cv1.bn.weight\r\n",
      "freezing model.17.m.0.cv1.bn.bias\r\n",
      "freezing model.17.m.0.cv2.conv.weight\r\n",
      "freezing model.17.m.0.cv2.bn.weight\r\n",
      "freezing model.17.m.0.cv2.bn.bias\r\n",
      "freezing model.18.conv.weight\r\n",
      "freezing model.18.bn.weight\r\n",
      "freezing model.18.bn.bias\r\n",
      "freezing model.20.cv1.conv.weight\r\n",
      "freezing model.20.cv1.bn.weight\r\n",
      "freezing model.20.cv1.bn.bias\r\n",
      "freezing model.20.cv2.conv.weight\r\n",
      "freezing model.20.cv2.bn.weight\r\n",
      "freezing model.20.cv2.bn.bias\r\n",
      "freezing model.20.cv3.conv.weight\r\n",
      "freezing model.20.cv3.bn.weight\r\n",
      "freezing model.20.cv3.bn.bias\r\n",
      "freezing model.20.m.0.cv1.conv.weight\r\n",
      "freezing model.20.m.0.cv1.bn.weight\r\n",
      "freezing model.20.m.0.cv1.bn.bias\r\n",
      "freezing model.20.m.0.cv2.conv.weight\r\n",
      "freezing model.20.m.0.cv2.bn.weight\r\n",
      "freezing model.20.m.0.cv2.bn.bias\r\n",
      "freezing model.21.conv.weight\r\n",
      "freezing model.21.bn.weight\r\n",
      "freezing model.21.bn.bias\r\n",
      "freezing model.23.cv1.conv.weight\r\n",
      "freezing model.23.cv1.bn.weight\r\n",
      "freezing model.23.cv1.bn.bias\r\n",
      "freezing model.23.cv2.conv.weight\r\n",
      "freezing model.23.cv2.bn.weight\r\n",
      "freezing model.23.cv2.bn.bias\r\n",
      "freezing model.23.cv3.conv.weight\r\n",
      "freezing model.23.cv3.bn.weight\r\n",
      "freezing model.23.cv3.bn.bias\r\n",
      "freezing model.23.m.0.cv1.conv.weight\r\n",
      "freezing model.23.m.0.cv1.bn.weight\r\n",
      "freezing model.23.m.0.cv1.bn.bias\r\n",
      "freezing model.23.m.0.cv2.conv.weight\r\n",
      "freezing model.23.m.0.cv2.bn.weight\r\n",
      "freezing model.23.m.0.cv2.bn.bias\r\n",
      "freezing model.24.m.0.weight\r\n",
      "freezing model.24.m.0.bias\r\n",
      "freezing model.24.m.1.weight\r\n",
      "freezing model.24.m.1.bias\r\n",
      "freezing model.24.m.2.weight\r\n",
      "freezing model.24.m.2.bias\r\n",
      "freezing model.25.conv.conv.weight\r\n",
      "UNFREEZING model.25.conv.conv.weight\r\n",
      "freezing model.25.conv.bn.weight\r\n",
      "UNFREEZING model.25.conv.bn.weight\r\n",
      "freezing model.25.conv.bn.bias\r\n",
      "UNFREEZING model.25.conv.bn.bias\r\n",
      "freezing model.25.linear.weight\r\n",
      "UNFREEZING model.25.linear.weight\r\n",
      "freezing model.25.linear.bias\r\n",
      "UNFREEZING model.25.linear.bias\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.001) with parameter groups 58 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\r\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mRandomResizedCrop(p=1, height=512, width=512, scale=(0.6, 1.0), ratio=(0.7, 1.11), interpolation=1), HorizontalFlip(p=0.2), Blur(p=0.2, blur_limit=(3, 7)), ToGray(p=0.1), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), CLAHE(p=0.2, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.2, gamma_limit=(80, 120), eps=None), ImageCompression(p=0.2, quality_lower=75, quality_upper=100, compression_type=0)\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_context/trai\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_context/val.ca\u001B[0m\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mnan anchors/target, nan Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mRunning kmeans for 9 anchors on 0 points...\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mWARNING ‚ö†Ô∏è switching strategies from kmeans to random init\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 5964.88it/s]                           \r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mthr=0.25: nan best possible recall, nan anchors past thr\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mn=9, img_size=512, metric_all=nan/nan-mean/best, past_thr=nan-mean: 11,18, 45,54, 57,93, 101,102, 103,119, 258,292, 293,302, 306,358, 383,497\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0mDone ‚ö†Ô∏è (original anchors better than new anchors, proceeding with original anchors)\r\n",
      "Plotting labels to runs/train-mlt/exp180/labels.jpg... \r\n",
      "zero-size array to reduction operation maximum which has no identity\r\n",
      "Image sizes 512 train, 512 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train-mlt/exp180\u001B[0m\r\n",
      "Starting training for 30 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       0/29      3.28G          0          0          0     0.9464          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.724      0.586      0.276      0.497      0.596\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       1/29      3.82G          0          0          0     0.5461          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.819      0.767      0.181      0.756      0.777\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       2/29      3.82G          0          0          0     0.2755          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.851      0.835      0.149      0.833      0.838\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       3/29      3.82G          0          0          0     0.1759          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.858       0.85      0.142      0.852      0.858\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       4/29      3.82G          0          0          0     0.1391          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.851      0.847      0.149      0.849      0.855\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       5/29      3.82G          0          0          0     0.1143          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.869      0.868      0.131      0.866       0.87\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       6/29      3.82G          0          0          0     0.1024          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.863       0.86      0.137      0.861       0.87\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       7/29      3.82G          0          0          0    0.09175          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.858      0.855      0.142      0.856      0.864\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       8/29      3.82G          0          0          0    0.08463          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.857      0.855      0.143      0.853      0.857\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       9/29      3.82G          0          0          0    0.07029          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.857      0.855      0.143      0.854      0.859\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      10/29      3.82G          0          0          0    0.07217          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.843      0.836      0.157      0.836       0.84\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      11/29      3.82G          0          0          0    0.06493          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.858      0.856      0.142      0.855      0.861\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      12/29      3.82G          0          0          0    0.06095          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.862      0.863      0.138       0.86      0.864\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      13/29      3.82G          0          0          0    0.05943          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.857      0.856      0.143      0.854      0.859\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      14/29      3.82G          0          0          0    0.05452          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.868      0.867      0.132      0.866      0.872\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      15/29      3.82G          0          0          0    0.04817          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0       0.87      0.869       0.13      0.868      0.873\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      16/29      3.82G          0          0          0    0.04696          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.871      0.871      0.129      0.869      0.873\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      17/29      3.82G          0          0          0    0.04396          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.866      0.866      0.134      0.865      0.868\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      18/29      3.82G          0          0          0    0.04354          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.864      0.864      0.136      0.862      0.867\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      19/29      3.82G          0          0          0    0.04152          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.866      0.866      0.134      0.865      0.869\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      20/29      3.82G          0          0          0    0.03769          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.865      0.864      0.135      0.863      0.867\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      21/29      3.82G          0          0          0    0.03589          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.866      0.865      0.134      0.864      0.869\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      22/29      3.82G          0          0          0    0.03428          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.867      0.866      0.133      0.865       0.87\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      23/29      3.82G          0          0          0    0.03589          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.866      0.864      0.134      0.864      0.869\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      24/29      3.82G          0          0          0    0.03333          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.866      0.865      0.134      0.864      0.868\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      25/29      3.82G          0          0          0    0.03373          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.864      0.864      0.136      0.863      0.868\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      26/29      3.82G          0          0          0    0.03032          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.865      0.863      0.135      0.863      0.868\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      27/29      3.82G          0          0          0       0.03          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.864      0.862      0.136      0.862      0.867\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      28/29      3.82G          0          0          0     0.0261          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.865      0.863      0.135      0.863      0.868\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      29/29      3.82G          0          0          0    0.02521          0   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all          0          0          0          0          0          0      0.864      0.862      0.136      0.861      0.867\r\n",
      "\r\n",
      "30 epochs completed in 0.808 hours.\r\n",
      "Optimizer stripped from runs/train-mlt/exp180/weights/last.pt, 15.7MB\r\n",
      "Optimizer stripped from runs/train-mlt/exp180/weights/best.pt, 15.7MB\r\n",
      "\r\n",
      "Validating runs/train-mlt/exp180/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 164 layers, 7697578 parameters, 0 gradients, 47.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "WARNING ‚ö†Ô∏è no labels found in val set, can not compute metrics without labels\r\n",
      "                   all       8971          0          0          0          0          0       0.87       0.87       0.13      0.869      0.873\r\n",
      "                   dry       8971       3765                                                  0.914      0.899     0.0862      0.906\r\n",
      "                 snowy       8971       2771                                                  0.926      0.846     0.0739      0.884\r\n",
      "                   wet       8971       2435                                                  0.771      0.867      0.229      0.816\r\n",
      "Results saved to \u001B[1mruns/train-mlt/exp180\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[32m(success).\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy ‚ñÅ‚ñÑ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet ‚ñÜ‚ñà‚ñá‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_cls 0.87062\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/P_snowy 0.92632\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_wet 0.77293\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_cls 0.87062\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/R_snowy 0.84477\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_wet 0.86836\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     best/cls_acc_val 0.873\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/epoch 16\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/mAP_0.5 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    best/mAP_0.5:0.95 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       best/precision 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          best/recall 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy 0.91356\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet 0.78275\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy 0.8267\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet 0.85592\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val 0.867\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 0.87033\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls 0.87048\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls 0.92609\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss 0.41264\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 8e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 8e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 8e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced \u001B[33mdark-fog-213\u001B[0m: \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/38v2wwy5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 18 media file(s), 1 artifact file(s) and 0 other file(s)\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20221208_112406-38v2wwy5/logs\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python multitasks/train.py --epochs 30 --img 512 --weights {best_weights} --data ../datasets/esmart_context/data.yaml --batch-size 32 --only_cls --freeze_all_but 8 25 --cut_img 0.5\n",
    "#!python multitasks/train.py --epochs 50 --img 512 --weights {best_weights} --data ../datasets/esmart_context/data.yaml  --batch-size 32 --only_cls --freeze_all_but 25 --cut_img 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/train-mlt/exp180\n"
     ]
    }
   ],
   "source": [
    "# get the last folder of the folder runs/train-mlt/\n",
    "list_of_files = glob.glob('runs/train-mlt/*')\n",
    "latest_exp_path = max(list_of_files, key=os.path.getmtime)\n",
    "print(latest_exp_path)\n",
    "last_weights = f\"{latest_exp_path}/weights/last.pt\"\n",
    "best_weights = f\"{latest_exp_path}/weights/best.pt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train again the detection task on esmart_wip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train only the detection using the weights form the previous run and freezing every layer in the backbone and classification head."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mselimgilon\u001B[0m (\u001B[33mesmart\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mmultitasks/train: \u001B[0mweights=yolov5s.pt, cfg=models/yolov5s_mlt.yaml, data=../datasets/esmart_wip/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=32, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-mlt, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, cut_img=0.0, patience=100, freeze=[], freeze_all=False, freeze_till=[0], freeze_all_but=[], only_cls=False, only_det=True, save_period=-1, seed=0, local_rank=-1, mlt=[0], entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 56 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic_det=1.0, mosaic_cls=0.0, mixup=0.0, copy_paste=0.0, cls_road_cond=1\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "2022-12-08 15:07:10.503027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-12-08 15:07:11.059316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 15:07:11.059369: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 15:07:11.059377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.13.6 is available!  To upgrade, please run:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/selim/Desktop/yolov5_multitask/wandb/run-20221208_150711-spfpa45d\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mradiant-planet-224\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/spfpa45d\u001B[0m\r\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "Overriding model.yaml nc=80 with nc=10\r\n",
      "Multitasks: True\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      " 25                 8  1    661763  models.common.Classify                  [512, 3]                      \r\n",
      "YOLOv5s_mlt summary: 222 layers, 7708362 parameters, 7708362 gradients, 48.1 GFLOPs\r\n",
      "\r\n",
      "Transferred 342/551 items from yolov5s.pt\r\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ‚úÖ\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.001) with parameter groups 58 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\r\n",
      "hyp['lr0'] 0.001\r\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mRandomResizedCrop(p=1, height=512, width=512, scale=(0.6, 1.0), ratio=(0.7, 1.11), interpolation=1), HorizontalFlip(p=0.2), Blur(p=0.2, blur_limit=(3, 7)), ToGray(p=0.1), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), CLAHE(p=0.2, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.2, gamma_limit=(80, 120), eps=None), ImageCompression(p=0.2, quality_lower=75, quality_upper=100, compression_type=0)\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/train.ca\u001B[0m\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210629_173500_5409.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_28266.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_37434.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_3444.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_6540.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_11838.jpg: 9 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_13446.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_8160.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13344.jpg: 8 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13470.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_42354.jpg: 30 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_9444.jpg: 13 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_33644.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_4542.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210715_091801_14454.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210724_113301_14106.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_12738.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_33438.jpg: 1 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg'\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/val.cache'\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/run_7_12704.jpg: 8 duplicate labels removed\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.92 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train-mlt/exp191/labels.jpg... \r\n",
      "Image sizes 512 train, 512 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train-mlt/exp191\u001B[0m\r\n",
      "Starting training for 15 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       0/14      4.22G     0.1182    0.01943    0.05489          0        171   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319    0.00316      0.143    0.00304   0.000625      0.683      0.336      0.317     0.0368      0.047\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       1/14      5.17G    0.09072    0.02432    0.03873          0        114   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.758      0.078     0.0567     0.0167      0.683      0.336      0.317     0.0368      0.047\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       2/14      5.17G    0.07808    0.02131    0.02897          0        136   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1307      0.821      0.163      0.141     0.0533      0.682      0.333      0.318     0.0296      0.068\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       3/14      5.17G    0.07237    0.01967    0.02282          0        111   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.692      0.186      0.183     0.0759      0.683      0.333      0.317      0.032      0.071\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       4/14      5.17G    0.06868    0.01855    0.01859          0        122   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1291      0.886      0.193       0.21     0.0901      0.684      0.333      0.316     0.0331      0.047\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       5/14      5.17G    0.06611    0.01793    0.01615          0        114   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1317      0.588      0.237      0.246       0.11      0.685      0.333      0.315     0.0343      0.049\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       6/14      5.17G    0.06459     0.0175    0.01411          0        118   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1320      0.375      0.274      0.255      0.116      0.683      0.343      0.317     0.0491       0.05\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       7/14      5.17G     0.0631    0.01708    0.01248          0        180   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1303      0.386      0.286      0.254      0.123      0.683      0.333      0.317     0.0308      0.069\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       8/14      5.17G    0.06202    0.01736    0.01173          0        140   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1308      0.422      0.278      0.256      0.119      0.685      0.336      0.315     0.0403      0.078\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       9/14      5.17G    0.06101    0.01703    0.01097          0        161   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1321      0.439      0.298      0.268      0.128      0.681      0.338      0.319     0.0375      0.042\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      10/14      5.17G    0.06102    0.01687    0.01072          0        137   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319      0.438      0.341      0.289       0.13      0.684      0.333      0.316     0.0331      0.047\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      11/14      5.17G    0.05997    0.01691    0.01012          0        145   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1286      0.435      0.314      0.284      0.135      0.685      0.333      0.315     0.0343      0.075\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      12/14      5.17G    0.05958    0.01671   0.009401          0        156   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1335      0.459      0.322      0.283      0.135      0.682      0.333      0.318     0.0296      0.042\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      13/14      5.17G    0.05891     0.0165   0.008961          0        114   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312      0.448      0.315      0.285      0.139      0.683      0.333      0.317      0.032      0.045\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      14/14      5.17G    0.05858    0.01649   0.009387          0         81   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1294      0.462      0.332      0.287      0.134      0.684      0.333      0.316     0.0331      0.047\r\n",
      "\r\n",
      "15 epochs completed in 0.254 hours.\r\n",
      "Optimizer stripped from runs/train-mlt/exp191/weights/last.pt, 15.7MB\r\n",
      "Optimizer stripped from runs/train-mlt/exp191/weights/best.pt, 15.7MB\r\n",
      "\r\n",
      "Validating runs/train-mlt/exp191/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 164 layers, 7697578 parameters, 0 gradients, 47.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1315      0.439      0.331      0.284       0.13      0.683      0.333      0.317      0.032      0.045\r\n",
      "           speed_limit        516        638      0.723      0.869      0.873      0.521\r\n",
      "                rw_tcd        516        198      0.405      0.561      0.517      0.192\r\n",
      "               highway        516        292      0.165      0.257      0.101     0.0217\r\n",
      "           interchange        516          4          1          0   0.000103   1.03e-05\r\n",
      "                 urban        516        132     0.0168    0.00758     0.0122    0.00317\r\n",
      "           rural-paved        516         51      0.326      0.294      0.201     0.0409\r\n",
      "                   dry        516        364                                                      1          0          0          0\r\n",
      "                 snowy        516         26                                                 0.0504          1       0.95     0.0959\r\n",
      "                   wet        516        126                                                      1          0          0          0\r\n",
      "Results saved to \u001B[1mruns/train-mlt/exp191\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[32m(success).\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñà‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÖ‚ñÜ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision ‚ñÅ‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_cls 0.68411\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/P_snowy 0.05233\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_wet 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_cls 0.33333\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/R_snowy 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_wet 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     best/cls_acc_val 0.047\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/epoch 10\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/mAP_0.5 0.28858\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    best/mAP_0.5:0.95 0.12994\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       best/precision 0.43838\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          best/recall 0.34097\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy 0.05233\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy 1.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val 0.047\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 0.12975\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 0.68346\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls 0.33333\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision 0.33141\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall 0.28415\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls 0.05039\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss 0.05858\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss 0.00939\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss 0.43916\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss 0.01649\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss 0.05768\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss 0.00889\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss 0.0\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss 0.00967\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 0.00014\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 0.00014\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 0.00014\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced \u001B[33mradiant-planet-224\u001B[0m: \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/spfpa45d\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 504 media file(s), 1 artifact file(s) and 0 other file(s)\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20221208_150711-spfpa45d/logs\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python multitasks/train.py --epochs 15 --img 512 --weights yolov5s.pt --data ../datasets/esmart_wip/data.yaml --batch-size 32 --only_det"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/train-mlt/exp191\n"
     ]
    }
   ],
   "source": [
    "list_of_files = glob.glob('runs/train-mlt/*')\n",
    "latest_exp_path = max(list_of_files, key=os.path.getmtime)\n",
    "print(latest_exp_path)\n",
    "last_weights = f\"{latest_exp_path}/weights/last.pt\"\n",
    "best_weights = f\"{latest_exp_path}/weights/best.pt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "weights_path = 'runs/train-mlt/exp112/weights/last.pt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mselimgilon\u001B[0m (\u001B[33mesmart\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mmultitasks/train: \u001B[0mweights=runs/train-mlt/exp112/weights/last.pt, cfg=models/yolov5s_mlt.yaml, data=../datasets/esmart_wip/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=32, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-mlt, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, cut_img=0.0, patience=100, freeze=[], freeze_all=False, freeze_till=[0], freeze_all_but=[], only_cls=False, only_det=True, save_period=-1, seed=0, local_rank=-1, mlt=[0], entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 56 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic_det=1.0, mosaic_cls=0.0, mixup=0.0, copy_paste=0.0, cls_road_cond=1\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "2022-12-08 16:25:01.183373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-12-08 16:25:01.757689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 16:25:01.757746: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 16:25:01.757754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.13.6 is available!  To upgrade, please run:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/selim/Desktop/yolov5_multitask/wandb/run-20221208_162502-1hi74hn6\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33molive-snow-236\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/1hi74hn6\u001B[0m\r\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "Overriding model.yaml nc=80 with nc=10\r\n",
      "Multitasks: True\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      " 25                 8  1    661763  models.common.Classify                  [512, 3]                      \r\n",
      "YOLOv5s_mlt summary: 221 layers, 7708362 parameters, 7708362 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 356/357 items from runs/train-mlt/exp112/weights/last.pt\r\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ‚úÖ\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.0001) with parameter groups 58 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\r\n",
      "hyp['lr0'] 0.0001\r\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mRandomResizedCrop(p=1, height=512, width=512, scale=(0.6, 1.0), ratio=(0.7, 1.11), interpolation=1), HorizontalFlip(p=0.2), Blur(p=0.2, blur_limit=(3, 7)), ToGray(p=0.1), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), CLAHE(p=0.2, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.2, gamma_limit=(80, 120), eps=None), ImageCompression(p=0.2, quality_lower=75, quality_upper=100, compression_type=0)\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/train.ca\u001B[0m\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210629_173500_5409.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_28266.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_083253_37434.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_3444.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_192517_6540.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_11838.jpg: 9 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_13446.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210630_202648_8160.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13344.jpg: 8 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_13470.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_42354.jpg: 30 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_110911_9444.jpg: 13 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_33644.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210711_174204_4542.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210715_091801_14454.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210724_113301_14106.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_12738.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/20210807_104028_33438.jpg: 1 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_2.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220126-081950 Data Log_529.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_11981.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_12384.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_18615.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2172.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_248.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_25404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_2575.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26117.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_26799.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_296.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_32875.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3381.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_34456.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_36905.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_39633.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_3970.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_404.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_405.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_4125.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7083.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_7331.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_8912.jpg'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/Log-20220318-064528 Data Log_9377.jpg'\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/val.cache'\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/run_7_12704.jpg: 8 duplicate labels removed\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m3.92 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train-mlt/exp202/labels.jpg... \r\n",
      "Image sizes 512 train, 512 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train-mlt/exp202\u001B[0m\r\n",
      "Starting training for 15 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       0/14      4.22G    0.04464    0.01337   0.002225          0        171   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1319      0.569      0.376      0.352       0.18      0.617      0.343      0.383     0.0507      0.052\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       1/14      5.17G    0.04481    0.01343   0.002315          0        111   ^C\r\n",
      "       1/14      5.17G    0.04481    0.01343   0.002315          0        111   \r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"multitasks/train.py\", line 805, in <module>\r\n",
      "    main(opt)\r\n",
      "  File \"multitasks/train.py\", line 699, in main\r\n",
      "    train(opt.hyp, opt, device, callbacks)\r\n",
      "  File \"multitasks/train.py\", line 428, in train\r\n",
      "    targets.to(device), targets_cls.to(device),\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python multitasks/train.py --epochs 15 --img 512 --weights {weights_path} --data ../datasets/esmart_wip/data.yaml --batch-size 32 --only_det"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mselimgilon\u001B[0m (\u001B[33mesmart\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mmultitasks/train: \u001B[0mweights=yolov5s.pt, cfg=models/yolov5s_mlt.yaml, data=../datasets/hybrid/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=32, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train-mlt, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, cut_img=0.0, patience=100, freeze=[], freeze_all=False, freeze_till=[0], freeze_all_but=[], only_cls=False, only_det=False, save_period=-1, seed=0, local_rank=-1, mlt=[0], entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0m‚ö†Ô∏è YOLOv5 is out of date by 56 commits. Use `git pull ultralytics master` or `git clone https://github.com/ultralytics/yolov5` to update.\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic_det=1.0, mosaic_cls=0.0, mixup=0.0, copy_paste=0.0, cls_road_cond=1\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "2022-12-08 18:29:32.415731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2022-12-08 18:29:33.198408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 18:29:33.198487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/selim/Desktop/yolov5_multitask/venv/lib/python3.8/site-packages/cv2/../../lib64:\r\n",
      "2022-12-08 18:29:33.198496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.13.6 is available!  To upgrade, please run:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/selim/Desktop/yolov5_multitask/wandb/run-20221208_182933-3m1i17z5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mstellar-capybara-241\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/3m1i17z5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\r\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/train-mlt', view at http://localhost:6006/\r\n",
      "Overriding model.yaml nc=80 with nc=10\r\n",
      "Multitasks: True\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \r\n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \r\n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\r\n",
      " 25                 8  1    661763  models.common.Classify                  [512, 3]                      \r\n",
      "YOLOv5s_mlt summary: 221 layers, 7708362 parameters, 7708362 gradients, 16.6 GFLOPs\r\n",
      "\r\n",
      "Transferred 342/357 items from yolov5s.pt\r\n",
      "hyp['lr0'] 0.0001\r\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed ‚úÖ\r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.0001) with parameter groups 58 weight(decay=0.0), 62 weight(decay=0.0005), 62 bias\r\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mRandomResizedCrop(p=1, height=512, width=512, scale=(0.6, 1.0), ratio=(0.7, 1.11), interpolation=1), HorizontalFlip(p=0.2), Blur(p=0.2, blur_limit=(3, 7)), ToGray(p=0.1), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), CLAHE(p=0.2, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.2, gamma_limit=(80, 120), eps=None), ImageCompression(p=0.2, quality_lower=75, quality_upper=100, compression_type=0)\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning '/home/selim/Desktop/datasets/hybrid/train/labels.cache' images \u001B[0m\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210629_173500_5409.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_083253_28266.jpg: 20 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_083253_37434.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_192517_3444.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_192517_6540.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_202648_11838.jpg: 9 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_202648_13446.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210630_202648_8160.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_110911_13344.jpg: 8 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_110911_13470.jpg: 4 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_110911_42354.jpg: 30 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_110911_9444.jpg: 13 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_174204_33644.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210711_174204_4542.jpg: 2 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210715_091801_14454.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210724_113301_14106.jpg: 3 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210807_104028_12738.jpg: 5 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/train/images/20210807_104028_33438.jpg: 1 duplicate labels removed\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/datasets/hybrid/val/labels.cache' images and \u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/datasets/hybrid/val/images/run_7_12704.jpg: 8 duplicate labels removed\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m4.02 anchors/target, 0.993 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\r\n",
      "Plotting labels to runs/train-mlt/exp207/labels.jpg... \r\n",
      "Image sizes 512 train, 512 val\r\n",
      "Using 8 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/train-mlt/exp207\u001B[0m\r\n",
      "Starting training for 20 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       0/19      5.14G       0.11     0.0157    0.05447  1.157e-05         20   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        515       1309   0.000238     0.0384   0.000129   1.94e-05      0.493      0.281      0.507      0.171      0.242\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       1/19      5.68G     0.0938    0.01781    0.04491  1.154e-05         14   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        519       1313   0.000749      0.208    0.00125   0.000314      0.498      0.271      0.502      0.181      0.237\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       2/19      5.68G    0.08348    0.01935    0.03994  1.152e-05          2   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        510       1299      0.012      0.318     0.0301    0.00734      0.512      0.277      0.488      0.199      0.245\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       3/19      5.68G    0.07477    0.01873    0.03429  1.152e-05         24   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1312       0.48      0.185      0.112     0.0284      0.514      0.271      0.486      0.201      0.241\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       4/19      5.68G    0.06914    0.01748    0.02959  1.152e-05         10   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        517       1314      0.347      0.252      0.139      0.041      0.504      0.255      0.496      0.191      0.227\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       5/19      5.68G    0.06542    0.01569    0.02499  1.152e-05         13   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        518       1317       0.38       0.27       0.18     0.0579      0.497      0.246      0.503       0.18      0.217\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       6/19      5.68G    0.06318    0.01491    0.02192  1.151e-05         13   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        517       1310      0.444      0.315      0.227     0.0752      0.494      0.247      0.506      0.173      0.216\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       7/19      5.68G    0.06104    0.01449    0.01941  1.152e-05         21   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        514       1306      0.444      0.326      0.233     0.0816       0.49      0.237       0.51       0.17       0.21\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       8/19      5.68G    0.06003    0.01422     0.0173  1.152e-05         24   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        519       1324       0.46      0.335      0.243     0.0868      0.493      0.242      0.507      0.173      0.213\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "       9/19      5.68G    0.05848    0.01389     0.0159  1.151e-05         10   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        512       1297        0.5      0.363      0.271     0.0995      0.499      0.245      0.501       0.18      0.217\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      10/19      5.68G     0.0578    0.01368    0.01467  1.151e-05          8   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        517       1314      0.509      0.358       0.28      0.102      0.492      0.234      0.508      0.174      0.207\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      11/19      5.68G    0.05691    0.01364    0.01366  1.151e-05         11   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        515       1310       0.52      0.369      0.293      0.108      0.493      0.237      0.507      0.175      0.209\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      12/19      5.68G    0.05627    0.01341    0.01261  1.151e-05         16   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1309      0.534      0.371      0.291      0.109      0.499      0.244      0.501      0.179      0.215\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      13/19      5.68G    0.05588     0.0133    0.01213  1.151e-05         10   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        515       1310      0.533      0.363      0.289      0.111       0.49      0.239       0.51      0.169      0.211\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      14/19      5.68G    0.05544    0.01319    0.01119  1.151e-05         13   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        520       1318      0.536      0.359      0.292      0.111       0.49      0.236       0.51      0.171      0.208\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      15/19      5.68G    0.05479    0.01313    0.01078  1.151e-05         35   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        523       1327      0.552      0.363      0.308      0.115      0.493       0.24      0.507      0.174      0.211\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      16/19      5.68G    0.05459     0.0131    0.01049  1.151e-05          5   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        508       1297      0.559      0.374      0.314      0.117      0.495      0.241      0.505      0.175      0.213\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      17/19      5.68G    0.05434    0.01311    0.01015  1.151e-05         21   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        517       1312       0.56      0.362      0.312      0.118      0.494      0.242      0.506      0.174      0.213\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      18/19      5.68G    0.05372    0.01298    0.01003  1.151e-05         20   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        513       1303       0.56      0.357      0.313      0.119      0.495      0.242      0.505      0.174      0.214\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss    rc_loss  Instances       Size\r\n",
      "      19/19      5.68G    0.05358    0.01297   0.009872  1.151e-05         14   \r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        517       1315      0.559      0.364      0.311       0.12      0.497      0.245      0.503      0.178      0.216\r\n",
      "\r\n",
      "20 epochs completed in 1.738 hours.\r\n",
      "Optimizer stripped from runs/train-mlt/exp207/weights/last.pt, 15.7MB\r\n",
      "Optimizer stripped from runs/train-mlt/exp207/weights/best.pt, 15.7MB\r\n",
      "\r\n",
      "Validating runs/train-mlt/exp207/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 163 layers, 7697578 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        518       1315      0.559      0.368      0.313      0.117      0.493      0.239      0.507      0.174      0.212\r\n",
      "           speed_limit        518        630      0.777      0.778      0.796      0.418\r\n",
      "                rw_tcd        518        204      0.516      0.382      0.338      0.102\r\n",
      "               highway        518        300      0.616      0.396      0.444      0.121\r\n",
      "           interchange        518          4          1          0     0.0014   0.000454\r\n",
      "                 urban        518        126       0.23      0.119     0.0746     0.0141\r\n",
      "           rural-paved        518         51      0.217      0.529      0.222     0.0487\r\n",
      "                   dry        518       3212                                                      1          0          0          0\r\n",
      "                 snowy        518       2277                                                  0.185        0.5      0.815       0.27\r\n",
      "                   wet        518       2590                                                  0.295      0.218      0.705      0.251\r\n",
      "Results saved to \u001B[1mruns/train-mlt/exp207\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[32m(success).\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                                                                                \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run history:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet ‚ñÅ‚ñÉ‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet ‚ñÅ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls ‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss ‚ñá‚ñà‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run summary:\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_cls 0.49462\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/P_snowy 0.18734\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/P_wet 0.29651\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_cls 0.24111\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/R_snowy 0.50305\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/R_wet 0.22029\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     best/cls_acc_val 0.213\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:           best/epoch 16\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         best/mAP_0.5 0.31362\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    best/mAP_0.5:0.95 0.11746\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       best/precision 0.55884\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:          best/recall 0.37423\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/P_snowy 0.18922\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/P_wet 0.30247\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/R_snowy 0.51093\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:        metrics/R_wet 0.22313\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  metrics/cls_acc_val 0.216\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:      metrics/mAP_0.5 0.11735\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: metrics/mAP_0.5:0.95 0.49336\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     metrics/prec_cls 0.23946\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:    metrics/precision 0.36756\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       metrics/recall 0.31256\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   metrics/recall_cls 0.18472\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/box_loss 0.05358\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:   train/cls_det_loss 0.00987\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/cls_loss 0.55924\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:       train/obj_loss 0.01297\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/box_loss 0.05506\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:     val/cls_det_loss 0.01455\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/cls_loss 1e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:         val/obj_loss 0.01191\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr0 1e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr1 1e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:                x/lr2 1e-05\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced \u001B[33mstellar-capybara-241\u001B[0m: \u001B[34m\u001B[4mhttps://wandb.ai/esmart/YOLOv5/runs/3m1i17z5\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Synced 5 W&B file(s), 344 media file(s), 1 artifact file(s) and 0 other file(s)\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Find logs at: \u001B[35m\u001B[1m./wandb/run-20221208_182933-3m1i17z5/logs\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python multitasks/train.py --epochs 20 --img 512 --weights yolov5s.pt --data ../datasets/hybrid/data.yaml --batch-size 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "weights_path = 'runs/train-mlt/exp162/weights/last.pt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The road conditions classification on esmart_context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the display of the logger works well in the terminal but sometimes doesn't show the title of the metrics when running from a notebook.\n",
    "Here is the list of the reported metrics (in order):\n",
    "\n",
    "*Class, Images, Instances, cls_P, cls_R, cls_fpr, cls_f1, cls_acc*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mmultitasks/val: \u001B[0mdata=../datasets/esmart_context/data.yaml, weights=['runs/train-mlt/exp162/weights/last.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-mlt, name=exp, exist_ok=False, half=False, dnn=False, only_det_eval=False, only_cls_eval=True, temperature=3.0\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 163 layers, 7697578 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_context/val.ca\u001B[0m\r\n",
      "                 Class     Images  Instances      cls_P      cls_R    cls_fpr   \r\n",
      "                   all       8971       8971      0.833      0.802      0.167       0.79      0.788\r\n",
      "                   dry       8971       3745      0.969      0.726     0.0307       0.83\r\n",
      "                 snowy       8971       2780      0.951      0.717     0.0491      0.817\r\n",
      "                   wet       8971       2446      0.579      0.964      0.421      0.723\r\n",
      "Speed: 0.1ms pre-process, 3.3ms inference, 0.5ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001B[1mruns/val-mlt/exp21\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python multitasks/val.py --img 512 --weights {weights_path} --data ../datasets/esmart_context/data.yaml  --batch-size 32 --only_cls_eval --temperature 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### The detections on esmart_wip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Class, Images, Instances, P, R, mAP50, mAP50-95*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mmultitasks/val: \u001B[0mdata=../datasets/esmart_wip/data.yaml, weights=['runs/train-mlt/exp162/weights/best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-mlt, name=exp, exist_ok=False, half=False, dnn=False, only_det_eval=True, only_cls_eval=False, temperature=1\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7960MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 163 layers, 7697578 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning '/home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/val.cache'\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING ‚ö†Ô∏è /home/selim/Desktop/esmart-ai-datasets/data/esmart_wip/run_7_12704.jpg: 8 duplicate labels removed\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        516       1311      0.375      0.343      0.333      0.171\r\n",
      "           speed_limit        516        628      0.863      0.962      0.972      0.693\r\n",
      "                rw_tcd        516        204      0.508      0.529      0.509      0.218\r\n",
      "               highway        516        300      0.388      0.273       0.21     0.0432\r\n",
      "           interchange        516          4          0          0          0          0\r\n",
      "                 urban        516        124     0.0419     0.0161     0.0123    0.00289\r\n",
      "           rural-paved        516         51      0.449      0.275      0.296     0.0706\r\n",
      "Speed: 0.1ms pre-process, 3.2ms inference, 0.8ms NMS per image at shape (32, 3, 512, 512)\r\n",
      "Results saved to \u001B[1mruns/val-mlt/exp26\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "weights_path = 'runs/train-mlt/exp162/weights/best.pt'\n",
    "!python multitasks/val.py --img 512 --weights {weights_path} --data ../datasets/esmart_wip/data.yaml --batch-size 32 --only_det_eval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export the model (work in progress)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mexport: \u001B[0mdata=None, weights=['runs/train-mlt/exp205/weights/last.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\r\n",
      "YOLOv5 üöÄ v6.2-293-gdee76bc1 Python-3.8.10 torch-1.12.0+cu102 CPU\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "YOLOv5s_mlt summary: 163 layers, 7697578 parameters, 0 gradients, 16.4 GFLOPs\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from runs/train-mlt/exp205/weights/last.pt with output shape torch.Size([1, 25200, 15]) for detection and torch.Size([1, 3]) for classification (59.3 MB)\r\n",
      "\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.12.0...\r\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success ‚úÖ 2.0s, saved as runs/train-mlt/exp205/weights/last.onnx (29.8 MB)\r\n",
      "\r\n",
      "Export complete (3.8s)\r\n",
      "Results saved to \u001B[1m/home/selim/Desktop/yolov5_multitask/runs/train-mlt/exp205/weights\u001B[0m\r\n",
      "Detect:          python predict.py --weights runs/train-mlt/exp205/weights/last.onnx \r\n",
      "Validate:        python val.py --weights runs/train-mlt/exp205/weights/last.onnx \r\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-mlt/exp205/weights/last.onnx')  \r\n",
      "Visualize:       https://netron.app\r\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights runs/train-mlt/exp205/weights/last.pt --include onnx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}